import json

# The content of this dictionary is a cleaned and merged version of the application's
# internal defaults and the platform configurations from the user's `default.json` profile.
# It serves as the master template for creating new user profiles.

DEFAULT_CONFIG = {
    "pre_translation_data": {},
    "post_translation_data": {},
    "exclusion_list_data": [],
    "auto_process_text_code_segment": False,
    "pre_translation_switch": False,
    "post_translation_switch": False,
    "prompt_dictionary_switch": False,
    "prompt_dictionary_data": [],
    "exclusion_list_switch": False,
    "characterization_switch": False,
    "characterization_data": [],
    "world_building_switch": False,
    "world_building_content": "",
    "writing_style_switch": False,
    "writing_style_content": "",
    "translation_example_switch": False,
    "translation_example_data": [],
    "few_shot_and_example_switch": False,
    "enable_api_failover": False,
    "backup_apis": [],
    "api_failover_threshold": 3,
    "user_thread_counts": 0,
    "auto_set_output_path": False,
    "request_timeout": 60,
    "response_check_switch": {
        "newline_character_count_check": False,
        "return_to_original_text_check": False,
        "residual_original_text_check": False,
        "reply_format_check": False,
        "untranslated_retry_limit": 3,
        "untranslated_reduction_rate": 0.5,
    },
    "keep_original_encoding": True,
    "translated_output_path": "",
    "translation_project": "AutoType",
    "retry_count": 3,
    "round_limit": 3,
    "enable_smart_round_limit": False,
    "smart_round_limit_multiplier": 2,
    "enable_fast_translate": False,
    "enable_line_breaks": False,
    "line_breaks_style": 0,
    "response_conversion_toggle": False,
    "opencc_preset": "s2twp.json",
    "tokens_limit_switch": False,
    "lines_limit": 20,
    "pre_line_counts": 3,
    "output_filename_suffix": "",
    "enable_bilingual_output": False,
    "bilingual_text_order": "translation_first",
    "polishing_mode_selection": "translated_text_polish",
    "polishing_pre_line_counts": 2,
    "cache_backup_limit": 10,
    "enable_cache_backup": True,
    "enable_auto_restore_ebook": True,
    "enable_dry_run": False,
    "enable_retry_backoff": True,
    "enable_session_logging": True,
    "enable_task_notification": True,
    "exclude_rule_str": "",
    "recent_projects": [],
    "label_output_path": "",
    "polishing_output_path": "",
    "platforms": {
        "sakura": {
            "tag": "sakura",
            "group": "local",
            "name": "SakuraLLM",
            "api_url": "http://127.0.0.1:8080",
            "api_key": "nokey",
            "api_format": "OpenAI",
            "icon": "sakura",
            "rpm_limit": 2000,
            "tpm_limit": 100000000,
            "model": "Sakura-v1.0",
            "top_p": 0.3,
            "temperature": 0.1,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": ["Sakura-v1.0"],
            "key_in_settings": [
                "api_url",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "frequency_penalty",
            ],
        },
        "murasaki": {
            "tag": "murasaki",
            "group": "local",
            "name": "Murasaki",
            "api_url": "http://127.0.0.1:8080",
            "api_key": "nokey",
            "api_format": "OpenAI",
            "icon": "murasaki",
            "rpm_limit": 2000,
            "tpm_limit": 100000000,
            "model": "murasaki-14b",
            "top_p": 0.9,
            "temperature": 0.7,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": ["murasaki-14b"],
            "key_in_settings": [
                "api_url",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "frequency_penalty",
            ],
        },
        "LocalLLM": {
            "tag": "LocalLLM",
            "group": "local",
            "name": "本地小模型",
            "api_url": "http://127.0.0.1:8080",
            "api_key": "nokey",
            "api_format": "OpenAI",
            "icon": "LocalLLM",
            "rpm_limit": 2000,
            "tpm_limit": 100000000,
            "model": "Qwen2.5-7B",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": ["Qwen2.5-7B"],
            "key_in_settings": [
                "api_url",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "frequency_penalty",
                "think_switch",
            ],
        },
        "cohere": {
            "tag": "cohere",
            "group": "online",
            "name": "Cohere",
            "api_url": "https://api.cohere.com",
            "api_key": "",
            "api_format": "Cohere",
            "icon": "cohere",
            "rpm_limit": 10,
            "tpm_limit": 9999999,
            "model": "command-r-plus",
            "top_p": 0.95,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": ["command-r-plus", "c4ai-aya-expanse-32b"],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "temperature",
                "top_p",
                "presence_penalty",
                "frequency_penalty",
            ],
        },
        "google": {
            "tag": "google",
            "group": "online",
            "name": "Google",
            "api_url": "https://generativelanguage.googleapis.com/v1beta",
            "api_key": "",
            "api_format": "Google",
            "icon": "google",
            "rpm_limit": 15,
            "tpm_limit": 320000,
            "model": "gemini-2.5-flash",
            "top_p": 0.95,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-3-pro"],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "temperature",
                "top_p",
                "think_switch",
                "thinking_budget",
                "presence_penalty",
                "frequency_penalty",
            ],
        },
        "openai": {
            "tag": "openai",
            "group": "online",
            "name": "OpenAI",
            "api_url": "https://api.openai.com/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "openai",
            "rpm_limit": 3500,
            "tpm_limit": 600000,
            "model": "gpt-3.5-turbo",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "structured_output_mode": 0,
            "auto_complete": False,
            "model_datas": ["gpt-3.5-turbo", "gpt-4", "gpt-4o", "gpt-4o-mini", "gpt-4-turbo"],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty",
                "think_switch",
                "think_depth",
                "structured_output_mode"
            ],
        },
        "deepseek": {
            "tag": "deepseek",
            "group": "online",
            "name": "DeepSeek",
            "api_url": "https://api.deepseek.com/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "deepseek",
            "rpm_limit": 4096,
            "tpm_limit": 10000000,
            "model": "deepseek-chat",
            "top_p": 1.0,
            "temperature": 1.3,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": ["deepseek-chat", "deepseek-reasoner"],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty",
            ],
        },
        "anthropic": {
            "tag": "anthropic",
            "group": "online",
            "name": "Anthropic",
            "api_url": "https://api.anthropic.com",
            "api_key": "",
            "api_format": "Anthropic",
            "icon": "anthropic",
            "rpm_limit": 2000,
            "tpm_limit": 100000000,
            "model": "claude-3-haiku",
            "top_p": 0.95,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": ["claude-3-5-haiku", "claude-sonnet-4", "claude-opus-4"],
            "key_in_settings": ["api_key", "model", "rpm_limit", "tpm_limit", "temperature", "top_p"],
        },
        "amazonbedrock": {
            "tag": "amazonbedrock",
            "group": "online",
            "name": "Amazon Bedrock",
            "region": "us-east-1",
            "access_key": "",
            "secret_key": "",
            "api_key": "",
            "api_url": "https://generativelanguage.googleapis.com",
            "api_format": "Amazon Bedrock",
            "icon": "amazonbedrock",
            "rpm_limit": 2000,
            "tpm_limit": 100000000,
            "model": "claude-3-haiku",
            "top_p": 0.95,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "region_datas": ["us-east-1", "us-east-2", "us-west-2", "eu-west-1"],
            "model_datas": [
                "anthropic.claude-3-haiku-20240307-v1:0",
                "anthropic.claude-3-sonnet-20240229-v1:0",
                "us.anthropic.claude-3-5-haiku-20241022-v1:0",
                "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
                "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
                "amazon.nova-lite-v1:0",
                "amazon.nova-micro-v1:0",
                "amazon.nova-pro-v1:0",
                "us.deepseek.r1-v1:0",
            ],
            "key_in_settings": [
                "region",
                "access_key",
                "secret_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "temperature",
                "top_p",
            ],
        },
        "xai": {
            "tag": "xai",
            "group": "online",
            "name": "xAI",
            "api_url": "https://api.x.ai/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "xai",
            "rpm_limit": 600,
            "tpm_limit": 1000000,
            "model": "grok-3-fast-beta",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": ["grok-3-fast-beta", "grok-3-mini-beta", "grok-3-beta"],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "think_switch",
                "think_depth",
            ],
        },
        "volcengine": {
            "tag": "volcengine",
            "group": "online",
            "name": "火山引擎",
            "api_url": "https://ark.cn-beijing.volces.com/api/v3",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "volcengine",
            "rpm_limit": 10000,
            "tpm_limit": 8000000,
            "model": "doubao-seed-1-6-flash-250615",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": [
                "doubao-seed-2-0-pro-260215",
                "doubao-seed-2-0-lite-260215",
                "doubao-seed-2-0-mini-260215",
                "doubao-seed-1-6-flash-250615",
                "doubao-seed-1-6-250615",
                "deepseek-v3-250324",
                "deepseek-r1-250528",
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty",
            ],
        },
        "dashscope": {
            "tag": "dashscope",
            "group": "online",
            "name": "阿里云百炼",
            "api_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "dashscope",
            "rpm_limit": 150,
            "tpm_limit": 1500000,
            "model": "qwen-turbo",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": ["qwen-turbo", "qwen-plus", "qwen-max", "qwen-long"],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty",
                "think_switch",
            ],
        },
        "zhipu": {
            "tag": "zhipu",
            "group": "online",
            "name": "智谱清言",
            "api_url": "https://open.bigmodel.cn/api/paas/v4",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "zhipu",
            "rpm_limit": 30,
            "tpm_limit": 100000,
            "model": "glm-4-flash",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": ["glm-4.5-flash", "glm-4.5-airx", "glm-4.5-air", "glm-4.5-x", "glm-4.5"],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty",
            ],
        },
        "yi": {
            "tag": "yi",
            "group": "online",
            "name": "零一万物",
            "api_url": "https://api.lingyiwanwu.com/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "yi",
            "rpm_limit": 10,
            "tpm_limit": 120000,
            "model": "yi-lightning",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": ["yi-lightning", "yi-large"],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty",
            ],
        },
        "moonshot": {
            "tag": "moonshot",
            "group": "online",
            "name": "月之暗面",
            "api_url": "https://api.moonshot.cn/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "moonshot",
            "rpm_limit": 3,
            "tpm_limit": 32000,
            "model": "moonshot-v1-8k",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": False,
            "model_datas": ["moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k", "kimi-thinking-preview"],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty",
            ],
        },
        "siliconflow": {
            "tag": "siliconflow",
            "group": "online",
            "name": "SiliconFlow",
            "api_url": "https://api.siliconflow.cn/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "siliconflow",
            "rpm_limit": 1000,
            "tpm_limit": 1000000,
            "model": "deepseek-ai/DeepSeek-V3",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "structured_output_mode": 0,
            "auto_complete": False,
            "model_datas": [
                "deepseek-ai/DeepSeek-V3",
                "deepseek-ai/DeepSeek-R1",
                "Pro/deepseek-ai/DeepSeek-V3",
                "Pro/deepseek-ai/DeepSeek-R1",
                "THUDM/glm-4-9b-chat",
                "01-ai/Yi-1.5-9B-Chat-16K"
            ],
            "key_in_settings": [
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty",
                "think_switch",
                "structured_output_mode"
            ],
        },
        "custom_openai": {
            "tag": "custom_openai",
            "group": "custom",
            "name": "自定义 OpenAI 格式",
            "api_url": "https://api.example.com/v1",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "custom",
            "rpm_limit": 60,
            "tpm_limit": 100000,
            "model": "gpt-4o",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "structured_output_mode": 0,
            "auto_complete": True,
            "model_datas": [
                "gpt-4o",
                "gpt-4o-mini",
                "claude-3-5-sonnet-20240620",
                "deepseek-chat"
            ],
            "key_in_settings": [
                "api_url",
                "api_key",
                "model",
                "rpm_limit",
                "tpm_limit",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty",
                "think_switch",
                "structured_output_mode"
            ]
        },
        "custom": {
            "tag": "custom",
            "group": "custom",
            "name": "自定义接口",
            "api_url": "",
            "api_key": "",
            "api_format": "OpenAI",
            "icon": "custom",
            "rpm_limit": 4096,
            "tpm_limit": 8000000,
            "model": "gpt-4o",
            "top_p": 1.0,
            "temperature": 1.0,
            "presence_penalty": 0.0,
            "frequency_penalty": 0.0,
            "think_switch": False,
            "think_depth": "low",
            "auto_complete": True,
            "model_datas": ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "claude-3-5-haiku", "claude-3-5-sonnet"],
            "format_datas": ["OpenAI", "Anthropic", "Google"],
            "extra_body": {},
            "key_in_settings": [
                "api_url",
                "api_key",
                "api_format",
                "rpm_limit",
                "tpm_limit",
                "model",
                "auto_complete",
                "top_p",
                "temperature",
                "presence_penalty",
                "frequency_penalty",
                "extra_body",
                "think_switch",
                "think_depth",
                "thinking_budget",
            ],
        },
    },
    "interface_language": "zh_CN",
    "enable_cache_backup": True,
    "enable_auto_restore_ebook": True,
    "enable_dry_run": False,
    "source_language": "auto",
    "target_language": "chinese_simplified",
    "target_platform": "sakura",
    "base_url": "http://127.0.0.1:8080",
    "model": "",
    "api_settings": {"translate": "sakura", "polish": "sakura"},
    "label_input_path": "",
    "interactive_mode": True,
    "translation_prompt_selection": {
        "last_selected_id": 100
    },
    "polishing_prompt_selection": {
        "last_selected_id": 10001
    },
}